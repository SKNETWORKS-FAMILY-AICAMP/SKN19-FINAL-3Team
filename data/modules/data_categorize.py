from openai import OpenAI
from dotenv import load_dotenv
from typing import Dict, Optional, Tuple
import re

load_dotenv()
client = OpenAI()

def clean_header_text(text: str) -> str:
    # HTML íƒœê·¸ ì œê±°
    text = re.sub(r"<[^>]+>", "", text)

    # Markdown ê°•ì¡° ì œê±°
    text = re.sub(r"\*\*(.*?)\*\*", r"\1", text)
    text = re.sub(r"\*(.*?)\*", r"\1", text)
    text = re.sub(r"__(.*?)__", r"\1", text)
    text = re.sub(r"_(.*?)_", r"\1", text)

    return text.strip()

def parse_markdown_header(text: str) -> Optional[Tuple[int, str]]:
    """
    ë§ˆí¬ë‹¤ìš´ í—¤ë”(#, ##, ### ...)ë¥¼ íŒŒì‹±
    ë°˜í™˜:
      - (depth, header_text)
      - í—¤ë”ê°€ ì•„ë‹ˆë©´ None
    """
    text = text.strip()

    md_match = re.match(r"^(#{1,6})\s+(.*)", text)
    if md_match:
        depth = len(md_match.group(1))
        header_text = md_match.group(2)

        header_text = clean_header_text(header_text)
        return depth, header_text
    
    html_match = re.match(
        r"^<h([1-6])[^>]*>(.*?)</h\1>",
        text,
        flags=re.IGNORECASE
    )
    if html_match:
        depth = int(html_match.group(1))
        header_text = html_match.group(2)

        header_text = clean_header_text(header_text)
        return depth, header_text

    return None

def build_sections(data: Dict):
    """
    label=1ì„ ê¸°ì¤€ìœ¼ë¡œ ì„¹ì…˜ ë‹¨ìœ„ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±
    ì›ë¬¸ ì¬ì¡°í•© ê°€ëŠ¥ (text ê·¸ëŒ€ë¡œ ì´ì–´ë¶™ì„)
    """
    sections = []
    buffer = []

    current_headers = {}

    for item in data:
        text = item["text"]
        buffer.append(text)

        # ğŸ”¹ í—¤ë” ë¬¸ì¥ ì²˜ë¦¬
        if item.get("type") == "header":
            parsed = parse_markdown_header(text)
            if parsed:
                depth, header_text = parsed

                # í˜„ì¬ depthì˜ í—¤ë” ê°±ì‹ 
                current_headers[depth] = header_text

                # í•˜ìœ„ depth ì œê±° (MarkdownNodeParserì™€ ë™ì¼)
                for d in list(current_headers.keys()):
                    if d > depth:
                        del current_headers[d]

        if item.get("label") == 1:
            header_path = "/" + "/".join(
                current_headers[d] for d in sorted(current_headers)
            )

            sections.append({
                "text": "".join(buffer),
                "header_path": header_path
            })

            buffer = []

    if buffer:
        header_path = "/" + "/".join(
            current_headers[d] for d in sorted(current_headers)
        )
        sections.append({
            "text": "".join(buffer),
            "header_path": header_path
        })

    return sections

def build_context(sections, idx, window=5):
    start = max(0, idx - window)
    end = min(len(sections), idx + window + 1)

    parts = []
    for i in range(start, end):
        parts.append(f"{sections[i]['text']}\n")

    return "\n\n".join(parts)

def build_user_prompt(category, sections):
    prompt = "header_path : " + sections["header_path"] + "\n" + "text : " + sections["text"] + "\n"
    str = "categories: \n"
    for i, depth_category in enumerate(category):
        str += f"\tdepth_{i} : "
        for s in depth_category:
            str += (s+", ")
        str += "\n"

    prompt += str
    return prompt

def build_index_prompt(context_text):
    return f"""
ë„ˆëŠ” ê¸°ìˆ  ë¬¸ì„œ ìƒ‰ì¸ ì „ë¬¸ê°€ì•¼.

ì•„ë˜ ë¬¸ì„œì˜ ë§¥ë½ì„ ì°¸ê³ í•´ì„œ
"í˜„ì¬ ì„¹ì…˜" í•˜ë‚˜ì— ëŒ€í•œ ìƒ‰ì¸ í•˜ë‚˜ë§Œ ìƒì„±í•´.

ê·œì¹™:
- ì (.)ìœ¼ë¡œ êµ¬ë¶„ëœ ê³„ì¸µ êµ¬ì¡°ë¡œ ë°˜ë“œì‹œ í•œ ì¤„ë§Œ ì¶œë ¥
- ì¹´í…Œê³ ë¦¬ëŠ” í˜„ì¬ ì¡´ì¬í•˜ëŠ” ì¹´í…Œê³ ë¦¬ë¥¼ ìµœìš°ì„ ìœ¼ë¡œ ì°¾ê³ , ì¡´ì¬í•˜ì§€ ì•Šì„ ê²½ìš° ìƒˆ ì¹´í…Œê³ ë¦¬ë¥¼ ìƒì„±
- **ë¹„ìŠ·í•œ ì´ë¦„ì˜ ì¹´í…Œê³ ë¦¬ëŠ” ë°˜ë“œì‹œ í•˜ë‚˜ë¡œ í†µí•©**
- ê° depthë³„ ì¹´í…Œê³ ë¦¬ëŠ” ë°˜ë“œì‹œ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ê±°ë‚˜ ìƒì„±ë˜ì–´ì•¼ í•¨
- ë¬¸ë§¥ì´ ì¡°ê¸ˆ ë‹¬ë¼ë„ ê°™ì€ ì˜ë¯¸ë©´ í•­ìƒ ê°™ì€ ìƒ‰ì¸
- ìƒ‰ì¸ë§Œ ì¶œë ¥ (ì„¤ëª… ê¸ˆì§€)

ìƒ‰ì¸ ì˜ˆì‹œ:


ë¬¸ì„œ ë§¥ë½:
----------------
{context_text}
----------------
"""

def generate_index(system_prompt: str, user_prompt: dict, model_name) -> str:
    response = client.chat.completions.create(
        model=model_name,
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ],
        temperature=0.0
    )

    return response.choices[0].message.content.strip()

def update_category_from_prompt(
    prompt: str,
    category: list
):
    lines = prompt.splitlines()
    return_prompt = prompt.replace("_", "").replace(" ", "")

    for line in lines:
        if not line.strip():
            continue

        parts = line.split(".")

        for depth, raw in enumerate(parts):
            # "_" ì™€ ê³µë°± ì œê±°
            cleaned = raw.replace("_", "").replace(" ", "").strip()

            if not cleaned:
                continue

            # category ê¹Šì´ê°€ ë¶€ì¡±í•˜ë©´ ìë™ í™•ì¥
            while depth >= len(category):
                category.append([])

            if cleaned not in category[depth]:
                category[depth].append(cleaned)

    return return_prompt, category

